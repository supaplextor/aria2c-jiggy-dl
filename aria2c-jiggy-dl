#!/usr/bin/perl
# git clone https://github.com/supaplextor/aria2c-jiggy-dl/ 

# http://mirror.debian.org/staticlist/Mirrors.masterlist
# http://geekofpassage.blogspot.com/
# (C) 2013 Scott Edwards <supadupa@gmail.com>
#
# jigdo cheating downloader.
# uses aria2
# hint: using "apt-get install balance" on 127.0.0.1:3128 to spread the load on all my squid servers.
# pass aria2 a list of mirrors (useful for 1M+ chunks)
# Note: uses 20 threads, to try and keep all (9 of my) proxy servers loaded with 2 urls concurrently at all times.

if (0 eq scalar(@ARGV)) {
	die "Pass at least one .jigdo file. All download files go here. Later, feed jigdo-lite build-dir directory for cache.";
}

use File::Basename qw(basename);
use List::Util qw/shuffle/;
use Data::Dumper;
use HTML::TokeParser::Simple;
use strict;
use warnings;

my $THREADS = 10;
my $site = "";
my $uri = "";
my @SITES;

sub mirrors {
	if (scalar(@SITES) > 0) {
		return
	}
	my $parser = HTML::TokeParser::Simple->new("list");
	my $tag;
	while ( $tag = $parser->get_tag('a') ) {
		if ( my $href = $tag->get_attr('href') ) {
			if ($href =~ m/\/debian/) {
				push(@SITES,$href)
			}
		}
	}
	return
}

my @childs;
my $pkg;
my $pkgs;
my $snapshot_url = '';

sub dq_dot_jigdo
{
	my $failsafe_servers = {};
	my $file = shift;
	open (J,"-|",qw(gzip -dc),$file) or die "Cannot gzip -dc $file: $!";
	while(<J>) {
		chomp;
		last if $_ eq "[Parts]";
	}
	while(<J>) {
		next unless defined $_;
		chomp;
		last if $_ eq "[Servers]";
		if (-1 eq index($_,":")) {
			next;
		}
		$pkg = basename $_;
		next if exists $pkgs->{$pkg};
		if ( (!-e $pkg) or (-s "$pkg.aria2") ) {
			my $l = "/".substr($_,1+index($_,":"));
			$pkgs->{$pkg}=$l;
		}
	}
	while(<J>) {
		next unless defined $_;
		chomp;
		if (-1 eq index($_,":")) {
			next;
		}
		if ($_ =~ m!(http.?://snapshot.debian.org.*)!) {
			$snapshot_url = $1;
			last;
		}
	}
	close J;
	my @pkgs = values %{$pkgs};
	undef $pkgs; 

	afork (\@pkgs,$THREADS,\&leech);

# TODO:  uh... make use of this I guess...
# echo "$1=="|tr '_-' '/+'|base64 -d|hexdump -e '16/1 "%02x" "\n"'
}

my $ec=-1;
if (!-s "list") {
	$ec = system qq(aria2c https://www.debian.org/mirror/list );

	if (0 eq $ec) {
		# success
	} else {
		die ("aria2c exit code $ec.");
	}
}
mirrors();
if (!-e "build-dir") {
	mkdir("build-dir");
}
if (!-e "pool") { # logs
	mkdir("pool");
}
for (@ARGV) {
	dq_dot_jigdo($_);
}

sub mfork ($$&) {
	my ($count, $max, $code) = @_;
	foreach my $c (1 .. $count) {
		wait unless $c <= $max;
		die "Fork failed: $!\n" unless defined (my $pid = fork);
		exit $code -> ($c) unless $pid;
	}
	1 until -1 == wait;
}

# sub afork (\@$&) {
sub afork {
	my ($data, $max, $code) = @_;
	my $c = 0;
	foreach my $data (@$data) {
		wait unless ++ $c <= $max;
		die "Fork failed: $!\n" unless defined (my $pid = fork);
		exit $code -> ($data) unless $pid;
	}
	1 until -1 == wait;
}
=head1
#by Abigail of perlmonks.org
#Some times you have a need to fork of several children, but you want to
#limit the maximum number of children that are alive at one time. Here
#are two little subroutines that might help you, mfork and afork. They are very similar.
#They take three arguments,
#and differ in the first argument. For mfork, the first
#argument is a number, indicating how many children should be forked. For
#afork, the first argument is an array - a child will be
#forked for each array element. The second argument indicates the maximum
#number of children that may be alive at one time. The third argument is a
#code reference; this is the code that will be executed by the child. One
#argument will be given to this code fragment; for mfork it will be an increasing number,
#starting at one. Each next child gets the next number. For afork, the array element is
#passed. Note that this code will assume no other children will be spawned,
#and that $SIG {CHLD} hasn't been set to IGNORE.
=cut

sub my_aria2c {
	my $ec=-1;
	my $self = shift;
	my $urls = join(" ",@_);
	#$ec = system qq(aria2c -x5 -q -k1M --all-proxy="http://127.0.0.1:128" $urls);

	$ec = system qq(aria2c -d $self->{dotdeb_save_dir} -l pool/log-aria2.$$ -x5 -q -k10M $urls);

	if (0 eq $ec) {
		print "$$ OK: $_[0] \n";
		unlink "pool/log-aria2.$$" or warn "Cannot unlink pool/log-aria2.$$: $!";;
		return $ec;
	} else {
		warn "aria2c returned exit code $ec and no idea why... See also pool/log-aria2.$$";
		die "I Quit!";
	}
	$ec = $ec >> 8;
	print "Error($ec): $_[0]\n";
	open L,"< pool/log-aria2.$$" or return $ec;
	print "$$ $_" while <L>;
	close L;
	return $ec;
}

sub mountpoints {
	my $self = shift;
	if (open my $fh, '<', '/proc/mounts') {
		while(<$fh>) {
			chomp;
			next unless $_;
#
# supaplex@wiseguy:~/usr/src/github-by-user/supaplextor/aria2c-jiggy-dl$ tail /proc/mounts 
# /dev/loop124 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-10.0.0-i386-DVD-3 iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# /dev/loop125 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-13.0.0-amd64-DVD-8 iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# /dev/loop126 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-12.11.0-amd64-DVD-1 iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# /dev/loop127 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-mac-13.2.0-amd64-netinst iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# /dev/loop128 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-9.11.0-i386-netinst iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# /dev/loop129 /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-edu-13.0.0-amd64-netinst iso9660 ro,relatime,nojoliet,check=s,map=n,blocksize=2048,uid=1000,iocharset=utf8 0 0
# 
			if ($_ =~ m/[^ ]+ ([^ ]+) (.*)/) {
#				mkdir -p ?
				if (-s "$2/" . $self->{dotdeb_dirname}) {
					# /home/supaplex/public_html/iso-images-FOSS/debian/build-dir/mounts/debian-edu-13.0.0-amd64-netinst
					my $save_to	= $self->{dotdeb_save_dir} . "/" . $self->{dotdeb_basename};
					my $r = "rsync -vP $2/"
						.quotemeta($self->{dotdeb_dirname}) 
						." " .quotemeta($save_to);
					warn "Running $r";
					my $ec = system qq($r);
					warn $ec if $ec;
				}
			} else {
				next;
			}

		}
	} else {
		die "Cannot open /proc/mounts for reading: $!";
	}
# So it's not in the pool directory, we have to check 
# mount points to it + pool/etc/foo.deb.	
}

sub leech {
	my $url = shift;
	my $self = {};
	@{ $self->{dir_branches} } = split(/\//,$url);
	$self->{dotdeb_basename} = pop(@{ $self->{dir_branches} });
	shift @{ $self->{dir_branches} };
	$self->{dotdeb_dirname} = join("/" => @{ $self->{dir_branches} });

	my $save_dir	=	"build-dir/" . $self->{dotdeb_dirname};
	-d $save_dir	||	system("mkdir -p ".quotemeta($save_dir));
	$self->{dotdeb_save_dir} = $save_dir;

	my $save_to	=	"$save_dir/" . $self->{dotdeb_basename}; 
	$self->{dotdeb_save_to} = $save_to;
	return 0 if -s $save_to;
	for(mountpoints($self)) {
		if (-s "$_/" . $self->{dotdeb_basename}) {
			warn "Found $_/" . $self->{dotdeb_basename};
			my $ec;
			$ec = system qq(mkdir -p build-dir/).quotemeta($self->{dotdeb_dirname});
			warn $ec if $ec;
			$ec = system qq(rsync -vP $_/).$self->{dotdeb_basename};
			warn $ec if $ec;
		}
	}
	my @urls;
	for (shuffle(@SITES)) {
		push @urls,$_.$url;
	}
	my $ec;
	@{ $self->{dir_caches}} = qw( local-apt-archives debian-730-amd64-1bd2 );
	for (@{ $self->{dir_caches}}) {
		$save_dir	= "$_/" . $self->{dotdeb_dirname};
		$save_to	= "$save_dir/" . $self->{dotdeb_basename}; 
		next unless -s $save_to;
		push @{ $self->{dotdeb_found}->{ $self->{dotdeb_basename} } }, $save_to;
		system ("ls -l ".quotemeta($save_to)); 
		system ("rsync -a ".quotemeta($save_to)." ".quotemeta("build-dir/".$self->{dotdeb_dirname}."/") ); 
		return 0;
	}

	$ec = my_aria2c($self,@urls);
	if (0 eq $ec) { return 0 }
	# $ec = my_aria2c("http://snapshot.debian.org/archive/debian/20130615T222935Z".$url);
	# warn "$snapshot_url/$url";
	$ec = my_aria2c($self,"$snapshot_url/$url");
	return $ec;
}
